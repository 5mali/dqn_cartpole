{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import datetime\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os \n",
    "import random \n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 324267*2# sys.argv[1]\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value) \n",
    "random.seed(seed_value) \n",
    "np.random.seed(seed_value) \n",
    "torch.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "# CartPole-v0 Environment\n",
    "env_id = \"CartPole-v0\"\n",
    "env = gym.make(env_id)\n",
    "env.seed(seed_value);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module): #base model\n",
    "    def __init__(self, num_inputs, num_actions, HIDDEN_LAYER_WIDTH):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.action_dim = num_actions\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_inputs, HIDDEN_LAYER_WIDTH),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_WIDTH, HIDDEN_LAYER_WIDTH),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_WIDTH, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "def get_action(policy_net, device, state, epsilon):\n",
    "    with torch.no_grad():\n",
    "        if random.random() > epsilon:\n",
    "            state   = torch.FloatTensor(state).unsqueeze(dim=0).to(device)\n",
    "            q_values = policy_net(state)\n",
    "            action  = q_values.max(dim=1)[1].item()\n",
    "        else:\n",
    "            action = random.randrange(self.action_dim)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, HIDDEN_LAYER_WIDTH):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.action_dim = num_actions\n",
    "        \n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_actions)\n",
    "        )\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        advantage = self.advantage(x)\n",
    "        value     = self.value(x)\n",
    "        return value + advantage  - advantage.mean()\n",
    "    \n",
    "#     def act(self, state, epsilon):\n",
    "#         with torch.no_grad():\n",
    "#             if random.random() > epsilon:\n",
    "#                 state   = torch.FloatTensor(state).unsqueeze(dim=0).to(self.device)\n",
    "#                 q_values = self.forward(state)\n",
    "#                 action  = q_values.max(dim=1)[1].item()\n",
    "#             else:\n",
    "#                 action = random.randrange(self.action_dim)\n",
    "#         return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list = ['D1QN_D1QN_Naive_1000_freq_100_324267_04171400',\n",
    "'D1QN-PER_D1QN_NaivePER_1000_freq_100_324267_04164957',\n",
    "'DQN_DQN_Naive_1000_freq_100_324267_04171233',\n",
    "'DQN-PER_DQN_NaivePER_1000_freq_100_324267_04164826',\n",
    "'DQN-PER-original_DQN_NaivePER_100000_freq_1000_324267_04163756',\n",
    "\n",
    "'D2QN_D2QN_Naive_1000_freq_100_324267_04170846',\n",
    "'D2QN-PER_D2QN_NaivePER_1000_freq_100_324267_04165444',\n",
    "\n",
    "'DuDQN_DuDQN_Naive_1000_freq_100_324267_04170649',\n",
    "'DuDQN-PER_DuDQN_NaivePER_1000_freq_100_324267_04165300',\n",
    "\n",
    "'DuD2QN_DuD2QN_Naive_1000_freq_100_324267_04170223',\n",
    "'DuD2QN-PER_DuD2QN_NaivePER_1000_freq_100_324267_04165910']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict = {}\n",
    "for exp in exp_list:\n",
    "    exp_name = exp.split('_')[0]\n",
    "    exp_dict[exp_name] = exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'DuDQN'\n",
    "log_name = exp_dict[experiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEM_FILE = './memories/' + log_name + '.mpk'\n",
    "\n",
    "# # Load Memories\n",
    "# with open(MEM_FILE, 'rb') as fpr:\n",
    "#     memories = np.array(list(pickle.load(fpr)))\n",
    "\n",
    "# visited_states = np.stack(memories[:,0]).squeeze()\n",
    "# actions = memories[:,1].astype(np.float32)\n",
    "# rewards = memories[:,2].astype(np.float32)\n",
    "# next_states = np.stack(memories[:,3]).squeeze()\n",
    "# done = memories[:,4].astype(np.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM CONFIG FILE\n",
    "config_path =  './configs/' + experiment + '.yaml' # sys.argv[2]\n",
    "config = yaml.safe_load(open(config_path,'r'))\n",
    "\n",
    "USE_GPU = config['USE_GPU']\n",
    "# Use CUDA\n",
    "USE_CUDA = torch.cuda.is_available() and USE_GPU\n",
    "\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# MODEL\n",
    "if (config['MODEL_NAME']=='D1QN' or config['MODEL_NAME']=='DQN' or config['MODEL_NAME']=='D2QN'):\n",
    "    # only one NN for estimating Q-values\n",
    "    policy_net = DQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "    policy_net = policy_net.to(device)\n",
    "\n",
    "\n",
    "elif (config['MODEL_NAME']=='DuDQN' or config['MODEL_NAME']=='DuD2QN'):\n",
    "    # one policy_net and one target_net\n",
    "    policy_net = DuelingDQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "\n",
    "    policy_net = policy_net.to(device)\n",
    "\n",
    "else: #default policy_net is D1QN\n",
    "    # only one NN for estimating Q-values\n",
    "    policy_net = DQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "\n",
    "    policy_net = policy_net.to(device)\n",
    "\n",
    "# # Load Learned Model Parameters\n",
    "MODEL_FILE = './models/'+ log_name + '.pth'\n",
    "policy_net.load_state_dict(torch.load(MODEL_FILE));\n",
    "policy_net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_pos_threshold = 2.4\n",
    "theta_threshold = 12 * 2 * np.pi / 360 # ~ 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qvalue(x_pos=0.0, x_vel=0.0, a_pos=0.0, a_vel=0.0):\n",
    "    state = [x_pos, x_vel, a_pos, a_vel]\n",
    "    with torch.no_grad():\n",
    "        state  = torch.FloatTensor(state).unsqueeze(dim=0).to(device)\n",
    "        q_values = policy_net(state)\n",
    "    \n",
    "    rects=plt.bar([0,0.35], \n",
    "            q_values.cpu().numpy().squeeze(0),\n",
    "            width = 0.35,\n",
    "            color=['r','g'])\n",
    "    plt.ylim([-200,200])\n",
    "    plt.xticks([0,0.35],['left','right'])\n",
    "    \n",
    "    for rect in rects:\n",
    "        height = 50#rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%.2f' % rect.get_height(),\n",
    "                ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea26d6d227d4228a20246007a66c6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x_pos', max=2.4, min=-2.4), FloatSlider(value=0.0, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q-values for each action for each of the state space\n",
    "interact(get_qvalue, x_pos=widgets.FloatSlider(min=-cart_pos_threshold, \n",
    "                                                max=cart_pos_threshold, \n",
    "                                                step=0.1, \n",
    "                                                value=0.0),\n",
    "                     x_vel=widgets.FloatSlider(min=-5, \n",
    "                                                max=5, \n",
    "                                                step=0.1, \n",
    "                                                value=0.0),\n",
    "                     a_pos=widgets.FloatSlider(min=-theta_threshold, \n",
    "                                                max=theta_threshold, \n",
    "                                                step=0.001, \n",
    "                                                value=0.0),\n",
    "                     a_vel=widgets.FloatSlider(min=-5, \n",
    "                                                max=5, \n",
    "                                                step=0.1, \n",
    "                                                value=0.0) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of 2d state space q-value function\n",
    "def get_heatmap(xvel=0.0, avel=0.0):\n",
    "    xpos = np.linspace(-cart_pos_threshold,cart_pos_threshold,50)\n",
    "    apos = np.linspace(-theta_threshold,theta_threshold,50)\n",
    "\n",
    "    XX,YY = np.meshgrid(xpos,apos)\n",
    "\n",
    "    q = np.zeros([len(xpos),len(apos),2])\n",
    "    ga = np.zeros([len(xpos),len(apos)])\n",
    "\n",
    "\n",
    "    for i in range(len(xpos)):\n",
    "        for j in range(len(apos)):\n",
    "            state = [xpos[i],xvel,apos[i],avel]\n",
    "            with torch.no_grad():\n",
    "                state  = torch.FloatTensor(state).unsqueeze(dim=0).to(device)\n",
    "                q_values = policy_net(state).cpu().numpy().squeeze(0)\n",
    "            q[i,j]=q_values\n",
    "            ga[i,j]=np.argmax(q_values)\n",
    "\n",
    "    q_left = q[:,:,0]\n",
    "    q_right = q[:,:,1]\n",
    "\n",
    "    fig,ax = plt.subplots(1,3,figsize=(10,3))\n",
    "    sns.heatmap(q_left, ax=ax[0], cbar=True, xticklabels=False, yticklabels=False,vmin=-200, vmax=200, cmap=\"Reds\")\n",
    "    sns.heatmap(q_right,ax=ax[1], cbar=True, xticklabels=False, yticklabels=False,vmin=-200, vmax=200, cmap=\"Greens\")\n",
    "    sns.heatmap(ga,ax=ax[2], cbar=True, xticklabels=False, yticklabels=False,vmin=0, vmax=1,cmap=['r','g'])\n",
    "\n",
    "    ax[0].set_title('Left')\n",
    "    ax[1].set_title('Right')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6e86d727024e8b8f0d5155c1ee53eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='xvel', max=5.0, min=-5.0), FloatSlider(value=0.0, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(get_heatmap, xvel=widgets.FloatSlider(min=-5, \n",
    "                                                max=5, \n",
    "                                                step=0.1, \n",
    "                                                value=0.0),\n",
    "                     avel=widgets.FloatSlider(min=-5, \n",
    "                                                max=5, \n",
    "                                                step=0.1, \n",
    "                                                value=0.0) );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
