{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/higgsfield/RL-Adventure/blob/master/1.dqn.ipynb\n",
    "# DQN without a frozen target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import datetime\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# %tensorboard --port=9706 --logdir ./runs\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT:  base \tSEED:  324267 \twriter_dir:  ./runs/D2QN_base_324267_20190829-045655\n"
     ]
    }
   ],
   "source": [
    "experiment = 'base'\n",
    "# FROM CONFIG FILE\n",
    "config_path =  './' + experiment + '.yaml' # sys.argv[2]\n",
    "config = yaml.safe_load(open(config_path,'r'))\n",
    "\n",
    "seed_value = 324267 # sys.argv[1]\n",
    "\n",
    "# # Writer will output to ./runs/ directory by default\n",
    "writer_dir = './runs/' + config['MODEL_NAME'] + '_' + experiment + '_' + str(seed_value) + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(writer_dir)\n",
    "print(\"EXPERIMENT: \", experiment, \"\\tSEED: \", seed_value, \"\\twriter_dir: \", writer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os \n",
    "import random \n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(seed_value) \n",
    "random.seed(seed_value) \n",
    "np.random.seed(seed_value) \n",
    "torch.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "# CartPole-v0 Environment\n",
    "env_id = \"CartPole-v0\"\n",
    "env = gym.make(env_id)\n",
    "env.seed(seed_value);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = config['USE_GPU']\n",
    "\n",
    "# Use CUDA\n",
    "USE_CUDA = torch.cuda.is_available() and USE_GPU\n",
    "\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "CUDA:  True\n",
      "DEVICE :  cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"PYTORCH: \", torch.__version__)\n",
    "print(\"CUDA: \", torch.cuda.is_available())\n",
    "print(\"DEVICE : \", device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLAY BUFFER\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module): #base model\n",
    "    def __init__(self, num_inputs, num_actions, HIDDEN_LAYER_WIDTH):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.action_dim = num_actions\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_inputs, HIDDEN_LAYER_WIDTH),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_WIDTH, HIDDEN_LAYER_WIDTH),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_WIDTH, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        with torch.no_grad():\n",
    "            if random.random() > epsilon:\n",
    "                state   = torch.tensor(state, dtype=torch.float32).unsqueeze(dim=0).to(device)\n",
    "                q_values = self.forward(state)\n",
    "                action  = q_values.max(dim=1)[1].item()\n",
    "            else:\n",
    "                action = random.randrange(self.action_dim)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        \n",
    "        self.action_dim = num_actions\n",
    "        \n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_actions)\n",
    "        )\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        advantage = self.advantage(x)\n",
    "        value     = self.value(x)\n",
    "        return value + advantage  - advantage.mean()\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        with torch.no_grad():\n",
    "            if random.random() > epsilon:\n",
    "                state   = torch.tensor(state, dtype=torch.float32).unsqueeze(dim=0).to(device)\n",
    "                q_values = self.forward(state)\n",
    "                action  = q_values.max(dim=1)[1].item()\n",
    "            else:\n",
    "                action = random.randrange(self.action_dim)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-greedy exploration\n",
    "\n",
    "epsilon_start = config['EPSILON_START']\n",
    "epsilon_final = config['EPSILON_FINAL']\n",
    "epsilon_decay = config['EPSILON_DECAY']\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f04e3411e48>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([epsilon_by_frame(i) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [32, 128]             640\n",
      "              ReLU-2                  [32, 128]               0\n",
      "            Linear-3                  [32, 128]          16,512\n",
      "              ReLU-4                  [32, 128]               0\n",
      "            Linear-5                    [32, 2]             258\n",
      "================================================================\n",
      "Total params: 17,410\n",
      "Trainable params: 17,410\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.13\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "if (config['MODEL_NAME']=='D1QN'):\n",
    "    # only one NN for estimating Q-values\n",
    "    model = DQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "elif (config['MODEL_NAME']=='DQN' or config['MODEL_NAME']=='D2QN'):\n",
    "    # one inference model and one target model\n",
    "    model = DQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    target = DQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "    target = target.to(device)\n",
    "\n",
    "elif (config['MODEL_NAME']=='DuDQN' or config['MODEL_NAME']=='DuD2QN'):\n",
    "    # one inference model and one target model\n",
    "    model = DuelingDQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    target = DuelingDQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])\n",
    "    target = target.to(device)\n",
    "    \n",
    "else: #default model is D1QN\n",
    "    # only one NN for estimating Q-values\n",
    "    model = DQN(env.observation_space.shape[0], \n",
    "                 env.action_space.n,\n",
    "                 config['HIDDEN_LAYER_WIDTH'])    \n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "print(model)\n",
    "summary(model, \n",
    "        input_size=(env.observation_space.shape[0],),\n",
    "        batch_size=config['BATCH_SIZE'], \n",
    "        device='cuda' if USE_CUDA else 'cpu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "if (config['OPTIMIZER']=='Adam'):\n",
    "    optimizer = optim.Adam(model.parameters(), \n",
    "                           lr=config['LEARNING_RATE'])\n",
    "elif (config['OPTIMIZER']=='SGD'):\n",
    "    optimizer = optim.SGD(model.parameters(), \n",
    "                           lr=config['LEARNING_RATE'])\n",
    "else: #default optimizer is Adam\n",
    "    optimizer = optim.Adam(model.parameters(), \n",
    "                           lr=config['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITERION\n",
    "if (config['CRITERION']=='MSE'):\n",
    "    criterion = nn.MSELoss()\n",
    "elif (config['CRITERION']=='HUBER'):\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "else: #default criterion is MSELoss\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLAY BUFFER\n",
    "replay_buffer = ReplayBuffer(capacity=config['REPLAY_BUFFER_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(current_model, target_model):\n",
    "    target.load_state_dict(model.state_dict())\n",
    "    target.eval()\n",
    "    \n",
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = torch.tensor(np.float32(state)      ,dtype=torch.float32).to(device)\n",
    "    next_state = torch.tensor(np.float32(next_state) ,dtype=torch.float32, requires_grad=False).to(device)\n",
    "    action     = torch.tensor(action                ,dtype=torch.long).to(device)\n",
    "    reward     = torch.tensor(reward                ,dtype=torch.float32).to(device)\n",
    "    done       = torch.tensor(done                  ,dtype=torch.float32).to(device)\n",
    "\n",
    "    q_values = model(state)\n",
    "    q_value  = q_values.gather(dim=1, index=action.unsqueeze(dim=1)).squeeze(dim=1)\n",
    "\n",
    "    #next_q_value\n",
    "    if (config['MODEL_NAME']=='D1QN'):\n",
    "        next_q_values = model(next_state)\n",
    "        next_q_value  = next_q_values.max(dim=1)[0]\n",
    "\n",
    "    elif (config['MODEL_NAME']=='DQN' or config['MODEL_NAME']=='DuDQN'):\n",
    "        next_q_values = target(next_state)\n",
    "        next_q_value  = next_q_values.max(dim=1)[0]\n",
    "        \n",
    "    elif (config['MODEL_NAME']=='D2QN' or config['MODEL_NAME']=='DuD2QN'):\n",
    "        next_q_values = model(next_state) #all q-values from current model\n",
    "        next_q_target_values = target(next_state) #all q-values from target model\n",
    "        next_q_value = next_q_target_values.gather(dim=1, \n",
    "                                                  index=torch.max(next_q_values, dim=1)[1].unsqueeze(dim=1)).squeeze(dim=1)\n",
    "        #q-values from target model by acting greedily on current model (double dqn)\n",
    "        \n",
    "    else: #Default is D1QN\n",
    "        next_q_values = model(next_state)\n",
    "        next_q_value  = next_q_values.max(dim=1)[0]\n",
    "    \n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "\n",
    "    loss = criterion(q_value, expected_q_value.detach())\n",
    "       \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (config['MODEL_NAME']=='DQN' or \n",
    "    config['MODEL_NAME']=='D2QN' or \n",
    "    config['MODEL_NAME']=='DuDQN' or\n",
    "    config['MODEL_NAME']=='DuD2QN'):\n",
    "    update_target(model, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 36s, sys: 52.9 s, total: 42min 29s\n",
      "Wall time: 41min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Training\n",
    "num_frames = config['TIMESTEPS']\n",
    "batch_size = config['BATCH_SIZE']\n",
    "gamma      = config['GAMMA']\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = model.act(state, epsilon)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        writer.add_scalar('episode_reward', episode_reward, global_step=frame_idx)\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "    if len(replay_buffer) > batch_size:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.item())\n",
    "        writer.add_scalar('loss', loss.item(), global_step=frame_idx)\n",
    "        \n",
    "#         for name, param in model.named_parameters():\n",
    "#             if param.requires_grad:\n",
    "#                 writer.add_histogram('model_'+ name, param.data, global_step=frame_idx)\n",
    "                \n",
    "#         if (config['MODEL_NAME']=='DQN' or config['MODEL_NAME']=='D2QN'):\n",
    "#             for name, param in target.named_parameters():\n",
    "#                 if param.requires_grad:\n",
    "#                     writer.add_histogram('target_'+ name, param.data, global_step=frame_idx)        \n",
    "    \n",
    "    if (config['MODEL_NAME']=='DQN' or \n",
    "        config['MODEL_NAME']=='D2QN' or \n",
    "        config['MODEL_NAME']=='DuDQN' or\n",
    "        config['MODEL_NAME']=='Du2DQN'):\n",
    "        if frame_idx % config['TARGET_UPDATE_FREQ'] == 0:\n",
    "            update_target(model, target)\n",
    "            \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
